{
    "name": "root",
    "gauges": {
        "Dog.Policy.Entropy.mean": {
            "value": 1.31321382522583,
            "min": 1.311187744140625,
            "max": 1.3830199241638184,
            "count": 36
        },
        "Dog.Policy.Entropy.sum": {
            "value": 65623.921875,
            "min": 46314.5703125,
            "max": 69381.7265625,
            "count": 36
        },
        "Dog.Environment.LessonNumber.goal_open_sides.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 36
        },
        "Dog.Environment.LessonNumber.goal_open_sides.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 36
        },
        "Dog.Step.mean": {
            "value": 9399962.0,
            "min": 7649975.0,
            "max": 9399962.0,
            "count": 36
        },
        "Dog.Step.sum": {
            "value": 9399962.0,
            "min": 7649975.0,
            "max": 9399962.0,
            "count": 36
        },
        "Dog.Policy.ExtrinsicValueEstimate.mean": {
            "value": 53.602455139160156,
            "min": 0.8852017521858215,
            "max": 61.88373565673828,
            "count": 36
        },
        "Dog.Policy.ExtrinsicValueEstimate.sum": {
            "value": 42881.96484375,
            "min": 465.6161193847656,
            "max": 49506.98828125,
            "count": 36
        },
        "Dog.Environment.EpisodeLength.mean": {
            "value": 999.0,
            "min": 921.6730769230769,
            "max": 999.0,
            "count": 36
        },
        "Dog.Environment.EpisodeLength.sum": {
            "value": 49950.0,
            "min": 25921.0,
            "max": 52099.0,
            "count": 36
        },
        "Dog.Environment.CumulativeReward.mean": {
            "value": 516.2498149654269,
            "min": 235.68586139380932,
            "max": 636.538873531784,
            "count": 36
        },
        "Dog.Environment.CumulativeReward.sum": {
            "value": 25812.490748271346,
            "min": 6363.518257632852,
            "max": 33100.02142365277,
            "count": 36
        },
        "Dog.Policy.ExtrinsicReward.mean": {
            "value": 516.2498149654269,
            "min": 235.68586139380932,
            "max": 636.538873531784,
            "count": 36
        },
        "Dog.Policy.ExtrinsicReward.sum": {
            "value": 25812.490748271346,
            "min": 6363.518257632852,
            "max": 33100.02142365277,
            "count": 36
        },
        "Dog.Losses.PolicyLoss.mean": {
            "value": 0.025217567108726746,
            "min": 0.02082628442440182,
            "max": 0.027968565153423695,
            "count": 36
        },
        "Dog.Losses.PolicyLoss.sum": {
            "value": 0.10087026843490698,
            "min": 0.07782176405501862,
            "max": 0.13172439560294152,
            "count": 36
        },
        "Dog.Losses.ValueLoss.mean": {
            "value": 447.2490762074789,
            "min": 288.58636175791423,
            "max": 628.5786639404297,
            "count": 36
        },
        "Dog.Losses.ValueLoss.sum": {
            "value": 1788.9963048299155,
            "min": 1030.1163681030273,
            "max": 3142.8933197021483,
            "count": 36
        },
        "Dog.Policy.LearningRate.mean": {
            "value": 1.8748173750639995e-05,
            "min": 1.8748173750639995e-05,
            "max": 7.085234638257665e-05,
            "count": 36
        },
        "Dog.Policy.LearningRate.sum": {
            "value": 7.499269500255998e-05,
            "min": 7.499269500255998e-05,
            "max": 0.00034160312613242,
            "count": 36
        },
        "Dog.Policy.Epsilon.mean": {
            "value": 0.10624936000000001,
            "min": 0.10624936000000001,
            "max": 0.12361742333333332,
            "count": 36
        },
        "Dog.Policy.Epsilon.sum": {
            "value": 0.42499744000000006,
            "min": 0.37085227,
            "max": 0.61386758,
            "count": 36
        },
        "Dog.Policy.Beta.mean": {
            "value": 0.0003218430639999999,
            "min": 0.0003218430639999999,
            "max": 0.0011885094243333334,
            "count": 36
        },
        "Dog.Policy.Beta.sum": {
            "value": 0.0012873722559999996,
            "min": 0.0012873722559999996,
            "max": 0.005731992242,
            "count": 36
        },
        "Dog.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 36
        },
        "Dog.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 36
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1756287956",
        "python_version": "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "D:\\Programme\\Anaconda\\envs\\mlagents\\Scripts\\mlagents-learn config/Dog.yaml --run-id=dog3 --resume",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.2.2+cu121",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1756295703"
    },
    "total": 7746.292901199951,
    "count": 1,
    "self": 0.008508999948389828,
    "children": {
        "run_training.setup": {
            "total": 0.07877210003789514,
            "count": 1,
            "self": 0.07877210003789514
        },
        "TrainerController.start_learning": {
            "total": 7746.205620099965,
            "count": 1,
            "self": 8.448077009001281,
            "children": {
                "TrainerController._reset_env": {
                    "total": 16.31710490002297,
                    "count": 1,
                    "self": 16.31710490002297
                },
                "TrainerController.advance": {
                    "total": 7721.396891490906,
                    "count": 140873,
                    "self": 4.944484058651142,
                    "children": {
                        "env_step": {
                            "total": 7312.942275126174,
                            "count": 140873,
                            "self": 6865.6546981261345,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 445.3752839008812,
                                    "count": 140873,
                                    "self": 7.634354904235806,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 437.7409289966454,
                                            "count": 139519,
                                            "self": 437.7409289966454
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 1.9122930991579778,
                                    "count": 140872,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 7663.979619692662,
                                            "count": 140872,
                                            "is_parallel": true,
                                            "self": 1036.7819820797886,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00047829997492954135,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.00023499998496845365,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.0002432999899610877,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.0002432999899610877
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 6627.197159312898,
                                                    "count": 140872,
                                                    "is_parallel": true,
                                                    "self": 17.37509802536806,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 21.112650290306192,
                                                            "count": 140872,
                                                            "is_parallel": true,
                                                            "self": 21.112650290306192
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 6540.919829400547,
                                                            "count": 140872,
                                                            "is_parallel": true,
                                                            "self": 6540.919829400547
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 47.789581596676726,
                                                            "count": 140872,
                                                            "is_parallel": true,
                                                            "self": 21.366700085345656,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 26.42288151133107,
                                                                    "count": 281744,
                                                                    "is_parallel": true,
                                                                    "self": 26.42288151133107
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 403.5101323060808,
                            "count": 140872,
                            "self": 5.207703907566611,
                            "children": {
                                "process_trajectory": {
                                    "total": 143.17488179833163,
                                    "count": 140872,
                                    "self": 143.0096379983006,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.16524380003102124,
                                            "count": 3,
                                            "self": 0.16524380003102124
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 255.12754660018254,
                                    "count": 175,
                                    "self": 178.6093280981877,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 76.51821850199485,
                                            "count": 5250,
                                            "self": 76.51821850199485
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.043546700035221875,
                    "count": 1,
                    "self": 0.0009324000566266477,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.04261429997859523,
                            "count": 1,
                            "self": 0.04261429997859523
                        }
                    }
                }
            }
        }
    }
}